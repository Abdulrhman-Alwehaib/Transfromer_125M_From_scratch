{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad2e6764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2b8b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Data/RAW_dataset/KnowlageDataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d34207",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31b0bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=[\"question\"],inplace=True)\n",
    "df.drop_duplicates(subset=[\"response\"],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fb45b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "849"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"question\"][0]) + len(df[\"response\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"question\"].str.len() + df[\"response\"].str.len() <= 512]\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91259142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"combined\"] = df[\"question\"] + \" \" +  df[\"response\"]\n",
    "df = df.assign(len=df['combined'].str.len()).sort_values('len').drop('len', axis=1)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b897e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df[df['response'].map(lambda x: x.isascii())]\n",
    "df = df[df['question'].map(lambda x: x.isascii())]\n",
    "\n",
    "df[\"question\"] = df[\"question\"].str.lower()\n",
    "df[\"response\"] = df[\"response\"].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcf694b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedText = []\n",
    "buffer = \"\"\n",
    "\n",
    "for i in range(len(df)):\n",
    "   \n",
    "    text = f\"<QUESTION> {df['question'].iloc[i]} <ANSWER> {df['response'].iloc[i]} <|endoftext|> \"\n",
    "    \n",
    "   \n",
    "    if len(buffer.split()) + len(text.split()) <= 350:\n",
    "        buffer += text\n",
    "    else:\n",
    "        \n",
    "        combinedText.append(buffer)\n",
    "        buffer = text\n",
    "        \n",
    "if buffer:\n",
    "    combinedText.append(buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91019d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combinedText[5].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizerGPT = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "customTokenizer = tokenizerGPT.train_new_from_iterator(combinedText, vocab_size=6000,new_special_tokens=[\"<QUESTION>\",\"<ANSWER>\"])\n",
    "\n",
    "customTokenizer.add_special_tokens({\n",
    "    'pad_token': '[PAD]'\n",
    "})\n",
    "customTokenizer.save_pretrained(\"./TOKENIZER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61603155",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Question ID: {customTokenizer.convert_tokens_to_ids('<QUESTION>')}\")\n",
    "print(f\"Answer ID: {customTokenizer.convert_tokens_to_ids('<ANSWER>')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "880b189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrivedTokenizer = AutoTokenizer.from_pretrained(\"./TOKENIZER/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b7c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "customTokenizer(\"Ask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bba60d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputTokenizer = retrivedTokenizer(\n",
    "    combinedText,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57d79b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = outputTokenizer[\"input_ids\"]\n",
    "masks = outputTokenizer[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfbac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(IDs,\"./Data/preproccessedData.pt\")\n",
    "torch.save(masks,\"./Data/preproccessedDataMASKS.pt\")\n",
    "\n",
    "tokenCOUNT = outputTokenizer[\"attention_mask\"].sum().item()\n",
    "tokenCOUNT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
